{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam Second Semester 2566 - Support Vector Machine (Raisin Problem)\n",
    "\n",
    "This exam problem has an objective to develop a support vector machine model to classify the raisin types whether they are Kecimen (class 0) or Besni (class 1) from 7 features.\n",
    "\n",
    "Cr: This dataset is adapted from CINAR I., KOKLU M. and TASDEMIR S., (2020). Classification of Raisin Grains Using Machine Vision and Artificial Intelligence Methods, Gazi Journal of Engineering Sciences, vol. 6, no. 3, pp. 200-209, December, 2020, DOI: https://doi.org/10.30855/gmbd.2020.03.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "# library written for this exam\n",
    "import utilsSVM as utils\n",
    "\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import random \n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We start the exam by first loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training dataset and test dataset\n",
    "\n",
    "# Read tab separated data\n",
    "data = np.loadtxt(os.path.join('Data', 'SVM_RaisinData_Train.txt'))\n",
    "\n",
    "# First 7 columns of data are features and the last column is the label.\n",
    "# Matrix X contains 7 features while vector y contains the label.\n",
    "\n",
    "X, y = data[:, :7], data[:, 7].astype(int)\n",
    "\n",
    "m = y.size  # number of training examples\n",
    "\n",
    "# Read tab separated testing data\n",
    "data_test = np.loadtxt(os.path.join('Data', 'SVM_RaisinData_Test.txt'))\n",
    "\n",
    "X_test, y_test = data_test[:, :7], data_test[:, 7].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((697, 7), (200, 7))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39643973,  0.00509791,  1.17536203, -1.07481261,  0.39371985,\n",
       "         0.34755079,  0.33975259],\n",
       "       [-0.72189398, -0.73016961, -0.63729811, -0.14769936, -0.72688149,\n",
       "         0.18563541, -0.74122882],\n",
       "       [ 1.62150837,  1.58158504,  1.25191026,  0.80258732,  1.5795776 ,\n",
       "        -1.12368024,  1.49643259]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a new dataset from 3 examples\n",
    "# This dataset will be used for the last question of this exam problem.\n",
    "\n",
    "# Read tab separated data\n",
    "data_new = np.loadtxt(os.path.join('Data', 'SVM_RaisinData_NewData.txt'))\n",
    "\n",
    "# This dataset contains only 7 features and does not have label.\n",
    "# Matrix X_new contains 7 features.\n",
    "\n",
    "X_new = data_new[:, 0:7]\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianKernel(x1, x2, sigma):\n",
    "    \"\"\"\n",
    "    Computes the radial basis function (RBF)\n",
    "    Returns a radial basis function kernel between x1 and x2.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x1 :  numpy ndarray\n",
    "        A vector of size (n, ), representing the first datapoint.\n",
    "    \n",
    "    x2 : numpy ndarray\n",
    "        A vector of size (n, ), representing the second datapoint.\n",
    "    \n",
    "    sigma : float\n",
    "        The bandwidth parameter for the Gaussian kernel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sim : float\n",
    "        The computed RBF between the two provided data points.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to return the similarity between `x1` and `x2`\n",
    "    computed using a Gaussian kernel with bandwidth `sigma`.\n",
    "    \"\"\"\n",
    "    sim = 0\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    sim = np.exp(-(np.sum(np.square(x1-x2)))/(2*np.square(sigma)))\n",
    "\n",
    "\n",
    "    # =============================================================\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_array = np.array([0.1,0.3,1,3])\n",
    "sigma_array = np.array([0.1,0.3,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset3Params(X, y, Xval, yval):\n",
    "    \"\"\"\n",
    "    Returns your choice of C and sigma for Part 3 of the exercise \n",
    "    where you select the optimal (C, sigma) learning parameters to use for SVM\n",
    "    with RBF kernel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        (m x n) matrix of training data where m is number of training examples, and \n",
    "        n is the number of features.\n",
    "    \n",
    "    y : array_like\n",
    "        (m, ) vector of labels for ther training data.\n",
    "    \n",
    "    Xval : array_like\n",
    "        (mv x n) matrix of validation data where mv is the number of validation examples\n",
    "        and n is the number of features\n",
    "    \n",
    "    yval : array_like\n",
    "        (mv, ) vector of labels for the validation data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    C, sigma : float, float\n",
    "        The best performing values for the regularization parameter C and \n",
    "        RBF parameter sigma.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Fill in this function to return the optimal C and sigma learning \n",
    "    parameters found using the cross validation set.\n",
    "    You can use `svmPredict` to predict the labels on the cross\n",
    "    validation set. For example, \n",
    "    \n",
    "        predictions = svmPredict(model, Xval)\n",
    "\n",
    "    will return the predictions on the cross validation set.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    You can compute the prediction error using \n",
    "    \n",
    "        np.mean(predictions != yval)\n",
    "    \"\"\"\n",
    "    # You need to return the following variables correctly.\n",
    "    C = 1\n",
    "    sigma = 0.3\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    C_array = np.array([0.1,0.3,1,3])\n",
    "    sigma_array = np.array([0.1,0.3,1,3])\n",
    "    \n",
    "    err_array = np.zeros([C_array.size, sigma_array.size,])\n",
    "    \n",
    "    for i in range(C_array.size):\n",
    "        for j in range(sigma_array.size):\n",
    "            model = utils.svmTrain(X, y, C_array[i], gaussianKernel, args = (sigma_array[j],))\n",
    "            predictions = utils.svmPredict(model, Xval)\n",
    "            pred_error = np.mean(predictions != yval)\n",
    "            \n",
    "            err_array[i,j] = pred_error\n",
    "            \n",
    "    ind = np.unravel_index(np.argmin(err_array, axis = None), err_array.shape)\n",
    "    C = C_array[ind[0]]\n",
    "    sigma = sigma_array[ind[1]]\n",
    "    \n",
    "    # ============================================================\n",
    "    return C, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 3.0\n"
     ]
    }
   ],
   "source": [
    "C, sigma = dataset3Params(X, y, X_test, y_test)\n",
    "\n",
    "# Train the SVM using the best parameters (C and sigma) we got from dataset3Params function\n",
    "model = utils.svmTrain(X, y, C, gaussianKernel, args=(sigma,))\n",
    "print(C, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.1\n",
    "sigma = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 86.23\n",
      "Test Accuracy: 88.50\n"
     ]
    }
   ],
   "source": [
    "p = utils.svmPredict(model, X)\n",
    "print('Training Accuracy: %.2f' % (np.mean(p == y) * 100))\n",
    "p_test = utils.svmPredict(model, X_test)\n",
    "print('Test Accuracy: %.2f' % (np.mean(p_test == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "p_1 = utils.svmPredict(model,X_new)\n",
    "print(p_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 3\n",
    "model = utils.svmTrain(X, y, C, utils.linearKernel, args=(sigma,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 86.37\n",
      "Test Accuracy: 90.00\n"
     ]
    }
   ],
   "source": [
    "p = utils.svmPredict(model, X)\n",
    "print('Training Accuracy: %.2f' % (np.mean(p == y) * 100))\n",
    "p_test = utils.svmPredict(model, X_test)\n",
    "print('Test Accuracy: %.2f' % (np.mean(p_test == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "p_1 = utils.svmPredict(model,X_new)\n",
    "print(p_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Support Vector Machine Problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
