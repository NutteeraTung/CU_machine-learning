{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bbb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import keras\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7898709",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt(r'D:\\M.eng\\Machine learning\\ML_project\\Data\\Water_Train_Data.txt')\n",
    "cv = np.loadtxt(r'D:\\M.eng\\Machine learning\\ML_project\\Data\\Water_CV_Data.txt')\n",
    "test = np.loadtxt(r'D:\\M.eng\\Machine learning\\ML_project\\Data\\Water_Test_Data.txt')\n",
    "#declare variable\n",
    "X = train[:,0:20]\n",
    "Y = train[:,20]\n",
    "X_val = cv[:,0:20]\n",
    "y_val = cv[:,20] \n",
    "X_test = test[:,0:20].T\n",
    "y_test = test[:,20] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d59656",
   "metadata": {},
   "source": [
    "<blockquote>Create model using NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607f721",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include only the rows having label = 0 or 1 (binary classification)\n",
    "X = train[:,0:20]\n",
    "\n",
    "# target variable\n",
    "Y = train[:,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf2ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d703191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a sigmoid activation function\n",
    "def sigmoid(z):\n",
    "    s = 1.0/ (1 + np.exp(-z))    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86034692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_architecture(X, Y):\n",
    "    # nodes in input layer\n",
    "    n_x = X.shape[0] \n",
    "    # nodes in hidden layer\n",
    "    n_h = 100          \n",
    "    # nodes in output layer\n",
    "    n_y = Y.shape[0] \n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print check\n",
    "network_architecture(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954027c0",
   "metadata": {},
   "source": [
    "You can adjust node in input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_network_parameters(n_x, n_h, n_y):\n",
    "    W1 = np.random.randn(n_h,n_x) * 0.01 # random initialization\n",
    "    b1 = np.zeros((n_h, 1)) # zero initialization\n",
    "    W2 = np.random.randn(n_y,n_h) * 0.01 \n",
    "    b2 = np.zeros((n_y, 1)) \n",
    "    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print check\n",
    "define_network_parameters(4796,100,4796)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1d1ee",
   "metadata": {},
   "source": [
    "the hidden layer and the output layer have a weight and bias term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, params):\n",
    "    Z1 = np.dot(params['W1'], X)+params['b1']\n",
    "    A1 = sigmoid(Z1)\n",
    "\n",
    "    Z2 = np.dot(params['W2'], A1)+params['b2']\n",
    "    A2 = sigmoid(Z2)\n",
    "    return {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42595b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print check\n",
    "forward_propagation(4796,_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53000923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(Predicted, Actual):\n",
    "    logprobs = np.multiply(np.log(Predicted), Actual)+ np.multiply(np.log(1-Predicted), 1-Actual)\n",
    "    cost = -np.sum(logprobs) / Actual.shape[0] \n",
    "    return np.squeeze(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbb179",
   "metadata": {},
   "source": [
    "compute network error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b090a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(params, activations, X, Y):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # output layer\n",
    "    dZ2 = activations['A2'] - Y # compute the error derivative \n",
    "    dW2 = np.dot(dZ2, activations['A1'].T) / m # compute the weight derivative \n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)/m # compute the bias derivative\n",
    "    \n",
    "    # hidden layer\n",
    "    dZ1 = np.dot(params['W2'].T, dZ2)*(1-np.power(activations['A1'], 2))\n",
    "    dW1 = np.dot(dZ1, X.T)/m\n",
    "    db1 = np.sum(dZ1, axis=1,keepdims=True)/m\n",
    "    \n",
    "    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "\n",
    "def update_parameters(params, derivatives, alpha = 0.001):\n",
    "    # alpha is the model's learning rate \n",
    "    \n",
    "    params['W1'] = params['W1'] - alpha * derivatives['dW1']\n",
    "    params['b1'] = params['b1'] - alpha * derivatives['db1']\n",
    "    params['W2'] = params['W2'] - alpha * derivatives['dW2']\n",
    "    params['b2'] = params['b2'] - alpha * derivatives['db2']\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00894fd8",
   "metadata": {},
   "source": [
    "You can adjust alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd908353",
   "metadata": {},
   "source": [
    "Implement Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3246e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X, Y, n_h, num_iterations=500):\n",
    "    n_x = network_architecture(X, Y)[0]\n",
    "    n_y = network_architecture(X, Y)[2]\n",
    "    \n",
    "    params = define_network_parameters(n_x, n_h, n_y)\n",
    "    for i in range(0, num_iterations):\n",
    "        results = forward_propagation(X, params)\n",
    "        error = compute_error(results['A2'], Y)\n",
    "        derivatives = backward_propagation(params, results, X, Y) \n",
    "        params = update_parameters(params, derivatives)    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f529d",
   "metadata": {},
   "source": [
    "Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y.reshape(1, Y.size)\n",
    "x = X.T\n",
    "model = neural_network(x, y, n_h = 10, num_iterations = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    results = forward_propagation(X, parameters)\n",
    "    print (results['A2'][0])\n",
    "    predictions = np.around(results['A2'])    \n",
    "    return predictions\n",
    "\n",
    "predictions = predict(model, x)\n",
    "print ('Training accuracy: %d' % float((np.dot(y,predictions.T) + np.dot(1-y,1-predictions.T))/float(y.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74326736",
   "metadata": {},
   "source": [
    "# Validation NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93459528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the data from test set\n",
    "X_val = cv[:,0:20].T\n",
    "\n",
    "# True labels for the test examples (must match the shape used in accuracy computation)\n",
    "y_val = cv[:,20] \n",
    "\n",
    "# Predict using the test set\n",
    "predictions = predict(model, X_val)\n",
    "\n",
    "# Calculate and print the accuracy (for binary classification)\n",
    "accuracy = float(\n",
    "    (np.dot(y_val, predictions.T) + np.dot(1 - y_val, 1 - predictions.T))\n",
    "    / y_val.size * 100\n",
    ")\n",
    "print('Validation accuracy: %d%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be674e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load validation data\n",
    "X_val = cv[:, 0:20].T\n",
    "y_val = cv[:, 20]  # True labels, should be (1600,)\n",
    "\n",
    "# Predict using the model\n",
    "predictions = predict(model, X_val)  # Ensure predictions are (1600,)\n",
    "\n",
    "# Reshape predictions if necessary\n",
    "predictions = predictions.ravel()  # Converts shape to (1600,)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322605f2",
   "metadata": {},
   "source": [
    "[[1415 0\n",
    "185 0]]\n",
    "TP = 0\n",
    "FP = 185\n",
    "TN = 1415\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix components\n",
    "TP = np.sum((predictions == 1) & (y_val == 1))  # True Positives\n",
    "TN = np.sum((predictions == 0) & (y_val == 0))  # True Negatives\n",
    "FP = np.sum((predictions == 1) & (y_val == 0))  # False Positives\n",
    "FN = np.sum((predictions == 0) & (y_val == 1))  # False Negatives\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = float(\n",
    "    (TP + TN) / y_val.size * 100\n",
    ")\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix of Validation:\")\n",
    "print(confusion_matrix)\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da2b900",
   "metadata": {},
   "source": [
    "# Learning curve NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define training and validation data\n",
    "X_train_full = X       \n",
    "y_train_full = Y      \n",
    "\n",
    "X_val_full = X_val     \n",
    "y_val_full = y_val    \n",
    "\n",
    "training_sizes = np.linspace(0.1, 1.0, 100)\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for size in training_sizes:\n",
    "    subset_size = int(size * X_train_full.shape[0])\n",
    "    \n",
    "    # Get subsets\n",
    "    X_subset = X_train_full[:subset_size].T          \n",
    "    y_subset = y_train_full[:subset_size].reshape(1, -1)\n",
    "\n",
    "    # Keep validation size fixed (recommendation)\n",
    "    X_val_subset = X_val_full.T if X_val_full.shape[0] == y_val_full.shape[0] else X_val_full \n",
    "    y_val_subset = y_val_full.reshape(1, -1)          \n",
    "\n",
    "    # Train the model\n",
    "    model = neural_network(X_subset, y_subset, n_h=100, num_iterations=500) #change the number of num_iteration\n",
    "\n",
    "    # Predict on training data\n",
    "    train_preds = predict(model, X_subset).flatten()\n",
    "    train_acc = float(\n",
    "        (np.dot(y_subset.flatten(), train_preds) + np.dot(1 - y_subset.flatten(), 1 - train_preds)) / y_subset.size * 100\n",
    "    )\n",
    "\n",
    "    # Predict on validation data\n",
    "    val_preds = predict(model, X_val_subset).flatten()\n",
    "    val_acc = float(\n",
    "        (np.dot(y_val_subset.flatten(), val_preds) + np.dot(1 - y_val_subset.flatten(), 1 - val_preds)) / y_val_subset.size * 100\n",
    "    )\n",
    "\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(training_sizes * 100, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(training_sizes * 100, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Training Set Size (%)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123bb22a",
   "metadata": {},
   "source": [
    "<blockquote>Create model using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c5b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[:,0:20] \n",
    "y_train = train[:,20] \n",
    "X_val = cv[:,0:20]\n",
    "y_val = cv[:,20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cfb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators = 500,        # Number of boosting rounds\n",
    "    learning_rate = 0.001,       # Step size at each iteration\n",
    "    max_depth = 4,             # Depth of each tree\n",
    "    subsample = 0.8,           # Fraction of samples to use for each tree\n",
    "    colsample_bytree = 0.8,    # Fraction of features to use for each tree\n",
    "    objective = 'binary:logistic',  # Binary classification task\n",
    "    eval_metric = 'logloss'    # Metric for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4cfc0",
   "metadata": {},
   "source": [
    "# Training and Validation XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix of Validation:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #          Predicted\n",
    "#           0     1\n",
    "# Actual  ---------\n",
    "#    0   | TN   FP |\n",
    "#    1   | FN   TP |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed66242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    # Example: if you used a scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)  # use transform, not fit_transform\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, f\"{cm[i, j]:.2f}\" if normalize else int(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "# Replace 'clf' with 'model'\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred) \n",
    "plot_confusion_matrix(confusion_mtx, classes=range(2))\n",
    "\n",
    "#visualize confusion matrix plot with blue one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00694e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee50660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_train = train[:,0:20] \n",
    "y_train = train[:,20] \n",
    "X_val = cv[:,0:20]\n",
    "y_val = cv[:,20] \n",
    "\n",
    "# Step 3: Define XGBoost model\n",
    "model = xgb.XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=4)\n",
    "\n",
    "# Step 4: Train model with evaluation sets\n",
    "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False  # Set to True to see training output\n",
    ")\n",
    "\n",
    "# Step 5: Extract training and validation loss using model.evals_result()\n",
    "eval_results = model.evals_result()\n",
    "\n",
    "# Step 6: Extract training and validation loss\n",
    "train_loss = eval_results['validation_0']['logloss']  # Training loss\n",
    "val_loss = eval_results['validation_1']['logloss']    # Validation loss\n",
    "\n",
    "# Step 7: Plot the learning curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss, label='Training Log Loss', color='blue')\n",
    "plt.plot(val_loss, label='Validation Log Loss', color='red')\n",
    "plt.xlabel('Number of Trees (Iterations)')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afadaec",
   "metadata": {},
   "source": [
    "<blockquote>Create model using decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score \n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "# import graphviz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "dt = DecisionTreeClassifier(criterion = 'entropy') #max_depth= 5, random_state=0\n",
    "dt.fit(X,Y)\n",
    "#training -> X,Y\n",
    "#validation -> X_val,y_val\n",
    "#test -> X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb0d15",
   "metadata": {},
   "source": [
    "# Training Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Accuracy:',accuracy_score(Y,dt.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on validation set\n",
    "y_pred = dt.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation Accuracy:',accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model using Gini as the criteria\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini') #max_depth= 10, random_state=0\n",
    "dt_gini.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9f4a7",
   "metadata": {},
   "source": [
    "Change max_dept-> the accuracy will be change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feec32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test validation set\n",
    "y_pred_gini = dt_gini.predict(X_val)\n",
    "print('Validation Accuracy:', accuracy_score(y_val,y_pred_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val,y_pred_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c454226",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[TP,FP],\n",
    "#  [FN,TN]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92fbfb",
   "metadata": {},
   "source": [
    "Decision Trees with Gini index provide better accuracy! So I'll show the model created by this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(y_pred_gini,return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75753d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(50,50), dpi = 100)\n",
    "tree.plot_tree(dt_gini, fontsize=14, ax=axes);\n",
    "fig.savefig('Decision.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e937092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting the feature names and class names into varaibles\n",
    "df = pd.read_excel(r'D:\\M.eng\\Machine learning\\ML_project\\WaterSafety_Data.xlsx')\n",
    "df = pd.DataFrame(df)\n",
    "df.iloc[0:0]\n",
    "fn = []\n",
    "for colum in df.iloc[0:0]:\n",
    "    fn.append(colum)\n",
    "print(fn)\n",
    "cn = ['0_is not safe','1_is safe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize=(50,50), dpi = 1000)\n",
    "tree.plot_tree(dt_gini, fontsize=14, ax=axes);\n",
    "tree.plot_tree(dt_gini,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True,\n",
    "               fontsize=14,\n",
    "               ax=axes);\n",
    "fig.savefig('Decision.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767bd65",
   "metadata": {},
   "source": [
    "# Decision Tree and Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffeefb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500,\n",
    "                            random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test validation set\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "print('Validation Accuracy:', accuracy_score(y_val,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with validation set\n",
    "# score = rf.score(X_val, y_val)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03aba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e476a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rf.estimators_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32188396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting the feature names and class names into varaibles\n",
    "df = pd.read_excel(r'D:\\M.eng\\Machine learning\\ML_project\\WaterSafety_Data.xlsx')\n",
    "df = pd.DataFrame(df)\n",
    "df.iloc[0:0]\n",
    "fn = []\n",
    "for colum in df.iloc[0:0]:\n",
    "    fn.append(colum)\n",
    "print(fn)\n",
    "cn = ['0_is not safe','1_is safe']\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize=(50,50),dpi=1000)\n",
    "tree.plot_tree(rf.estimators_[0],\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True);\n",
    "fig.savefig('rf_individualtree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0db891",
   "metadata": {},
   "source": [
    "# Test Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c177fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy:',accuracy_score(y_test,y_pred)) #test using entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7004835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd195aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy:',accuracy_score(y_test,y_pred_gini)) #test using Gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba72fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184c4265",
   "metadata": {},
   "source": [
    "# Test NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07311345",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[:,0:20].T #test with test set\n",
    "\n",
    "# True labels for the test examples (must match the shape used in accuracy computation)\n",
    "y_test = test[:,20] \n",
    "\n",
    "# Predict using the test set\n",
    "predictions = predict(model, X_test)\n",
    "\n",
    "# Calculate and print the accuracy (for binary classification)\n",
    "accuracy = float(\n",
    "    (np.dot(y_test, predictions.T) + np.dot(1 - y_test, 1 - predictions.T))\n",
    "    / y_val.size * 100\n",
    ")\n",
    "print('Test accuracy: %d%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ff972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix components\n",
    "TP = np.sum((predictions == 1) & (y_test == 1))  # True Positives\n",
    "TN = np.sum((predictions == 0) & (y_test == 0))  # True Negatives\n",
    "FP = np.sum((predictions == 1) & (y_test == 0))  # False Positives\n",
    "FN = np.sum((predictions == 0) & (y_test == 1))  # False Negatives\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = float(\n",
    "    (TP + TN) / y_test.size * 100\n",
    ")\n",
    "\n",
    "# Print confusion matrix and accuracy\n",
    "print(\"Confusion Matrix of Testing:\")\n",
    "print(confusion_matrix)\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9517304",
   "metadata": {},
   "source": [
    "\"\"\" [[TP, FP],\n",
    " [FN, TN]] \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7592b1",
   "metadata": {},
   "source": [
    "Model Explanations\n",
    "From my confusion matrix foused\n",
    "a large number of false negatives (FN), which means model is missing a lot of positive cases and incorrectly classifying them as negative. This suggests that your model is not very good at identifying the positive class (1). \n",
    "\n",
    "Your model isn't making any predictions for the negative class (0), which could mean:\n",
    "\n",
    "The model is biased towards predicting the positive class (1)/(TN) and never predicting 0.\n",
    "It could be that your model is overfitting to the positive class, or that the negative class (0) is underrepresented in the training data (leading the model to favor the positive class).\n",
    "\n",
    "Model => Overfitting improve by applied to xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8745e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('NN_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8af84",
   "metadata": {},
   "source": [
    "# Test XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = joblib.load('xgb_model.pkl')\n",
    "\n",
    "# Predict test set using the loaded model\n",
    "X_test = test[:,0:20]\n",
    "y_pred = model.predict(X_test)\n",
    "new_predictions = model.predict(X_test)\n",
    "new_predictions\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix of Validation:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c39ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict list set for testing data\n",
    "model = joblib.load('xgb_model.pkl')\n",
    "# New sample with 20 features\n",
    "new_sample = [2.4864, 13.9879, 1.2767, 2.5472, 0.6646, 4.2778, 0.6198, 0.8900, 1.0629, 1.3389,\n",
    "             0.5301, 0.6185, 3.2371, 2.6852, 0.0402, 23.6282, 2.8132, 0.6108, 0.1690, 0.0063]\n",
    "new_sample = np.array(new_sample).reshape(1, -1)\n",
    "\n",
    "\n",
    "# Check the shape\n",
    "print(f\"Shape of new data (single sample): {new_sample.shape}\")  # Should print (1, 20)\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(new_sample)\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Prediction for the new sample:\", prediction)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix of Validation:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc509572",
   "metadata": {},
   "source": [
    "When using the same data that is X_test = [2.4864, 13.9879, 1.2767, 2.5472, 0.6646, 4.2778, 0.6198, 0.8900, 1.0629, 1.3389,\n",
    "             0.5301, 0.6185, 3.2371, 2.6852, 0.0402, 23.6282, 2.8132, 0.6108, 0.1690, 0.0063]\n",
    "The model of NN predict y = 0 accuracy = 88.4%\n",
    "The model of XGBoost y = 0 with accuracy = 96.5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
